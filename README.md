<p align="center">
  <img src="https://img.shields.io/badge/ğŸ¦¾-NoonVision-667eea?style=for-the-badge&labelColor=764ba2" alt="NoonVision">
</p>

<h1 align="center">ğŸ¦¾ NoonVision</h1>

<p align="center">
  <strong>Hands-Free AI Vision Assistant for the Visually Impaired</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python" alt="Python">
  <img src="https://img.shields.io/badge/YOLOv8-Object%20Detection-green?style=flat-square" alt="YOLOv8">
  <img src="https://img.shields.io/badge/Gradio-UI%20Framework-orange?style=flat-square" alt="Gradio">
  <img src="https://img.shields.io/badge/License-MIT-yellow?style=flat-square" alt="License">
</p>

<p align="center">
  <em>Empowering independence through voice-controlled computer vision</em>
</p>

---

## ğŸŒŸ Overview

**NoonVision** is a revolutionary accessibility tool that enables blind and visually impaired individuals to understand their surroundings using just their voice. No buttons, no complex interfaces â€” simply say "Detect" and let AI describe the world around you.

Built with state-of-the-art YOLOv8 object detection and natural text-to-speech, NoonVision provides real-time audio descriptions of detected objects, making navigation and daily tasks more accessible than ever.

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ¤ **100% Voice Controlled** | No buttons required â€” just speak to interact |
| ğŸ‘ï¸ **80+ Object Categories** | Detects people, vehicles, animals, furniture, electronics, and more |
| âš¡ **Real-Time Processing** | Results delivered in 1-2 seconds |
| ğŸ”Š **Natural Audio Feedback** | Human-like speech describes your surroundings |
| ğŸ“± **Works Everywhere** | Browser-based â€” no installation needed |
| â™¿ **Accessibility First** | Designed from the ground up for visually impaired users |

---

## ğŸ¯ How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   ğŸ‘¤ User says "Detect"                                     â”‚
â”‚        â†“                                                    â”‚
â”‚   ğŸ“· Camera captures current frame                          â”‚
â”‚        â†“                                                    â”‚
â”‚   ğŸ¤– YOLOv8 AI analyzes the image                          â”‚
â”‚        â†“                                                    â”‚
â”‚   ğŸ”Š "I can see a person and a laptop in front of you"     â”‚
â”‚        â†“                                                    â”‚
â”‚   ğŸ¤ System returns to listening mode                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—£ï¸ Voice Commands

NoonVision responds to natural speech. Try any of these:

- **"Detect"** â€” Scan your surroundings
- **"What do you see?"** â€” Same as detect
- **"Scan"** â€” Quick scan
- **"Look"** â€” Check what's in front
- **"Identify"** â€” Identify objects
- **"Check"** â€” See what's around

---

## ğŸš€ Quick Start

### Using Hugging Face Spaces (Recommended)

1. **Visit** the live demo at [NoonVision on Hugging Face](https://huggingface.co/spaces/your-username/noonvision)
2. **Click** anywhere on the page to initialize
3. **Allow** camera and microphone permissions
4. **Say** "Detect" and listen!

### Running Locally

```bash
# Clone the repository
git clone https://github.com/your-username/noonvision.git
cd noonvision

# Install dependencies
pip install -r requirements.txt

# Run the application
python app.py
```

---

## ğŸ› ï¸ Technical Stack

| Component | Technology |
|-----------|------------|
| **Object Detection** | YOLOv8m (Medium) |
| **Web Framework** | Gradio 4.19.2 |
| **Speech Recognition** | Web Speech API |
| **Text-to-Speech** | Google TTS (gTTS) |
| **Camera Access** | HTML5 getUserMedia |
| **Backend** | Python 3.10+ |

---

## ğŸ“‹ Requirements

### Software
- Python 3.10 or higher
- Modern web browser (Chrome or Edge recommended)

### Hardware
- Webcam or device camera
- Microphone
- Speakers or headphones

### Browser Compatibility

| Browser | Support |
|---------|---------|
| âœ… Chrome | Full support (recommended) |
| âœ… Edge | Full support |
| âš ï¸ Firefox | Limited speech recognition |
| âš ï¸ Safari | Limited speech recognition |

---

## ğŸ¨ Features in Detail

### ğŸ¤ Voice Recognition
- Continuous listening for trigger words
- Works in noisy environments
- Supports natural language variations

### ğŸ“· Smart Camera
- Auto-starts when page loads
- Optimized for various lighting conditions
- Works with front and rear cameras

### ğŸ¤– AI Detection
- Powered by YOLOv8 â€” state-of-the-art object detection
- Detects 80+ object categories
- Confidence scoring for accuracy
- Bounding box visualization

### ğŸ”Š Audio Response
- Natural, conversational speech
- Clear pronunciation of object names
- Handles singular/plural correctly
- "I can see **a person** and **two chairs**..."

---

## ğŸ”® Future Roadmap

- [ ] **Scene Description** â€” Describe spatial relationships between objects
- [ ] **Distance Estimation** â€” "There's a chair about 3 feet ahead"
- [ ] **Text Reading (OCR)** â€” Read signs, labels, and documents
- [ ] **Face Recognition** â€” Identify known individuals
- [ ] **Offline Mode** â€” Work without internet connection
- [ ] **Mobile App** â€” Native iOS/Android applications
- [ ] **Multi-language** â€” Support for additional languages

---

## ğŸ¤ Contributing

We welcome contributions from the community! Whether it's:

- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“š Documentation improvements
- ğŸŒ Translations

Please read our contributing guidelines before submitting a PR.

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **[Ultralytics](https://ultralytics.com/)** â€” For the incredible YOLOv8 model
- **[Gradio](https://gradio.app/)** â€” For the intuitive web framework
- **[Hugging Face](https://huggingface.co/)** â€” For hosting and community support
- **The Accessibility Community** â€” For invaluable feedback and testing

---

## ğŸ“¬ Contact & Support

- **Issues:** [GitHub Issues](https://github.com/your-username/noonvision/issues)
- **Discussions:** [GitHub Discussions](https://github.com/your-username/noonvision/discussions)

---

<p align="center">
  <strong>Made with â¤ï¸ for Accessibility</strong>
</p>

<p align="center">
  <em>Because everyone deserves to see the world</em>
</p>

---

<p align="center">
  <img src="https://img.shields.io/badge/â­-Star%20this%20repo-yellow?style=for-the-badge" alt="Star">
</p>